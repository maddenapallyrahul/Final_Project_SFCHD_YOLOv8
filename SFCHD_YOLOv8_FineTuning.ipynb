{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_zJOx5x6DcQ",
        "outputId": "1aa1c72a-841a-4545-b76c-3415f7b04f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "CUDA available: True | Torch: 2.6.0+cu124 | Python: 3.11.13\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access dataset and verify GPU environment for YOLO training\n",
        "# Cell 1\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# (Menu: Runtime â†’ Change runtime type â†’ Hardware accelerator: GPU) then:\n",
        "import torch, platform\n",
        "print(\"CUDA available:\", torch.cuda.is_available(), \"| Torch:\", torch.__version__, \"| Python:\", platform.python_version())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset paths (matches SFCHD dataset structure in Drive)\n",
        "# Cell 2\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_ROOT = Path(\"/content/drive/MyDrive/QY_final_dataset\")\n",
        "RAW_IMAGES = DATA_ROOT / \"images\"     # contains all image files\n",
        "RAW_LABELS = DATA_ROOT / \"labels\"     # contains YOLO label files\n",
        "YOLO_ROOT  = DATA_ROOT / \"yolo\"       # train/val split will be stored here\n",
        "\n",
        "print(DATA_ROOT, \"OK\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdZimJBb6K3F",
        "outputId": "813a71e5-ed76-4348-e91f-83c1967ae3f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/QY_final_dataset OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy dataset from Drive -> /content once; skips on later runs\n",
        "# Cell 3\n",
        "\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "DRIVE_ROOT = Path(\"/content/drive/MyDrive/QY_final_dataset\")\n",
        "LOCAL_ROOT = Path(\"/content/SFCHD\")\n",
        "for sub in [\"images\", \"labels\"]:\n",
        "    src = DRIVE_ROOT/sub\n",
        "    dst = LOCAL_ROOT/sub\n",
        "    if not dst.exists():\n",
        "        dst.mkdir(parents=True, exist_ok=True)\n",
        "        subprocess.run([\"rsync\", \"-ah\", \"--info=progress2\", f\"{src}/\", f\"{dst}/\"], check=True)\n",
        "\n",
        "print(\"DATA READY at:\", LOCAL_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeBbRSmsLlrf",
        "outputId": "3e6f570a-d062-494c-b822-f2a1a812aa25"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA READY at: /content/SFCHD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4\n",
        "\n",
        "yaml_text = \"\"\"path: /content/SFCHD\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "nc: 7\n",
        "names: [helmet, no-helmet, vest, no-vest, person, head, full-body]  # update to your exact labels\n",
        "\"\"\"\n",
        "open(\"/content/sfchd_local.yaml\", \"w\").write(yaml_text)\n",
        "print(\"Wrote /content/sfchd_local.yaml\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJjSIsoBLsGm",
        "outputId": "f8bb0730-f5f6-4641-d034-1542ae296337"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote /content/sfchd_local.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create YOLO folder structure locally (fast, safe to re-run)\n",
        "# Cell 5\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Keep this aligned with Cell 3 (local mirror) and Cell 4 (YAML path)\n",
        "YOLO_ROOT = Path(\"/content/SFCHD\")\n",
        "\n",
        "dirs = [\n",
        "    YOLO_ROOT / \"images/train\",\n",
        "    YOLO_ROOT / \"labels/train\",\n",
        "    YOLO_ROOT / \"images/val\",\n",
        "    YOLO_ROOT / \"labels/val\",\n",
        "    YOLO_ROOT / \"images/test\",\n",
        "    YOLO_ROOT / \"labels/test\",\n",
        "]\n",
        "\n",
        "for d in dirs:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Created/verified YOLO structure under:\", YOLO_ROOT)\n",
        "for d in dirs:\n",
        "    print(\"-\", d)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k56C6AtP6dmE",
        "outputId": "c3bb2e63-400e-4e66-9ebd-0f1eab9f32ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created/verified YOLO structure under: /content/SFCHD\n",
            "- /content/SFCHD/images/train\n",
            "- /content/SFCHD/labels/train\n",
            "- /content/SFCHD/images/val\n",
            "- /content/SFCHD/labels/val\n",
            "- /content/SFCHD/images/test\n",
            "- /content/SFCHD/labels/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6 â€” Auto-detect source folders and copy matched pairs to local train/ (idempotent)\n",
        "\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# 1) Candidate source locations (order matters)\n",
        "candidates = [\n",
        "    (Path(\"/content/drive/MyDrive/QY_final_dataset/images\"),\n",
        "     Path(\"/content/drive/MyDrive/QY_final_dataset/labels\")),\n",
        "    (Path(\"/content/drive/MyDrive/QY_final_dataset/yolo/train/images\"),\n",
        "     Path(\"/content/drive/MyDrive/QY_final_dataset/yolo/train/labels\")),\n",
        "    (Path(\"/content/SFCHD/images\"),   # if you already mirrored raw here\n",
        "     Path(\"/content/SFCHD/labels\")),\n",
        "]\n",
        "\n",
        "# 2) Pick the first non-empty pair\n",
        "def count_imgs(p): return sum(1 for _ in p.glob(\"*\"))\n",
        "def count_labs(p): return sum(1 for _ in p.glob(\"*.txt\"))\n",
        "\n",
        "SRC_IMG = SRC_LAB = None\n",
        "for img_dir, lab_dir in candidates:\n",
        "    if img_dir.exists() and lab_dir.exists() and count_imgs(img_dir) > 0 and count_labs(lab_dir) > 0:\n",
        "        SRC_IMG, SRC_LAB = img_dir, lab_dir\n",
        "        break\n",
        "\n",
        "assert SRC_IMG is not None, \"No non-empty source found. Check where your dataset actually lives in Drive.\"\n",
        "print(\"Using source:\", SRC_IMG, \"|\", SRC_LAB)\n",
        "\n",
        "# 3) Local YOLO target (matches your YAML)\n",
        "YOLO_ROOT = Path(\"/content/SFCHD\")\n",
        "DST_IMG = YOLO_ROOT / \"images/train\"\n",
        "DST_LAB = YOLO_ROOT / \"labels/train\"\n",
        "DST_IMG.mkdir(parents=True, exist_ok=True)\n",
        "DST_LAB.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 4) Skip if already populated\n",
        "if any(DST_IMG.glob(\"*\")) and any(DST_LAB.glob(\"*.txt\")):\n",
        "    print(\"Train folders already populated â€” skipping copy.\")\n",
        "else:\n",
        "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\", \".webp\"}\n",
        "    images = {p.stem: p for p in SRC_IMG.iterdir() if p.is_file() and p.suffix.lower() in exts}\n",
        "    labels = {p.stem: p for p in SRC_LAB.glob(\"*.txt\") if p.is_file()}\n",
        "    common = sorted(set(images) & set(labels))\n",
        "\n",
        "    copied_i = copied_l = 0\n",
        "    for stem in common:\n",
        "        si, sl = images[stem], labels[stem]\n",
        "        ti, tl = DST_IMG / si.name, DST_LAB / sl.name\n",
        "        if not ti.exists():\n",
        "            shutil.copy2(si, ti); copied_i += 1\n",
        "        if not tl.exists():\n",
        "            shutil.copy2(sl, tl); copied_l += 1\n",
        "\n",
        "    print(f\"Matched pairs: {len(common)}\")\n",
        "    print(f\"Newly copied -> images: {copied_i}, labels: {copied_l}\")\n",
        "\n",
        "# 5) Final counts\n",
        "n_img = sum(1 for _ in DST_IMG.glob(\"*\"))\n",
        "n_lab = sum(1 for _ in DST_LAB.glob(\"*.txt\"))\n",
        "print(f\"Train counts -> images: {n_img}, labels: {n_lab}\")\n",
        "if n_img != n_lab:\n",
        "    print(\"âš ï¸ Warning: count mismatch in train/. Investigate missing pairs.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHLEkOb76fhS",
        "outputId": "66000398-540b-40f1-e5d4-fcc53a330d2b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using source: /content/drive/MyDrive/QY_final_dataset/yolo/train/images | /content/drive/MyDrive/QY_final_dataset/yolo/train/labels\n",
            "Matched pairs: 11135\n",
            "Newly copied -> images: 11135, labels: 11135\n",
            "Train counts -> images: 11135, labels: 11135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Set validation split ratio\n",
        "val_ratio = 0.1\n",
        "\n",
        "# Get list of all image files in train/images\n",
        "all_images = list((YOLO_ROOT / \"train/images\").glob(\"*.*\"))\n",
        "\n",
        "# Shuffle for randomness\n",
        "random.shuffle(all_images)\n",
        "\n",
        "# Calculate how many images to move\n",
        "val_count = int(len(all_images) * val_ratio)\n",
        "\n",
        "# Move files to validation folders\n",
        "moved_val_i = moved_val_l = 0\n",
        "for img_path in all_images[:val_count]:\n",
        "    label_path = YOLO_ROOT / \"train/labels\" / (img_path.stem + \".txt\")\n",
        "\n",
        "    # Move image\n",
        "    shutil.move(str(img_path), YOLO_ROOT / \"val/images\" / img_path.name)\n",
        "    moved_val_i += 1\n",
        "\n",
        "    # Move label if it exists\n",
        "    if label_path.exists():\n",
        "        shutil.move(str(label_path), YOLO_ROOT / \"val/labels\" / label_path.name)\n",
        "        moved_val_l += 1\n",
        "\n",
        "print(f\"Moved images -> val/images: {moved_val_i}\")\n",
        "print(f\"Moved labels -> val/labels: {moved_val_l}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQRrMHYi6ub7",
        "outputId": "de6c95d8-4369-4675-b5db-88f0c2889023"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved images -> val/images: 0\n",
            "Moved labels -> val/labels: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8\n",
        "from pathlib import Path\n",
        "\n",
        "YOLO_ROOT = Path(\"/content/drive/MyDrive/QY_final_dataset\") / \"yolo\"\n",
        "\n",
        "yaml_text = f\"\"\"\n",
        "path: {YOLO_ROOT}\n",
        "train: train/images\n",
        "val: val/images\n",
        "names:\n",
        "  0: person\n",
        "  1: safety_helmet\n",
        "  2: safety_clothing\n",
        "  3: other_clothing\n",
        "  4: head\n",
        "  5: blurred_clothing\n",
        "  6: blurred_head\n",
        "\"\"\"\n",
        "\n",
        "with open(\"sfchd.yaml\", \"w\") as f:\n",
        "  f.write(yaml_text.strip() + \"\\n\")\n",
        "\n",
        "print(\"Wrote sfchd.yaml:\\n\")\n",
        "print(open(\"sfchd.yaml\").read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fxjwwov09n4c",
        "outputId": "282b864b-117a-4d2e-ebd5-ef2f17632eed"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote sfchd.yaml:\n",
            "\n",
            "path: /content/drive/MyDrive/QY_final_dataset/yolo\n",
            "train: train/images\n",
            "val: val/images\n",
            "names:\n",
            "  0: person\n",
            "  1: safety_helmet\n",
            "  2: safety_clothing\n",
            "  3: other_clothing\n",
            "  4: head\n",
            "  5: blurred_clothing\n",
            "  6: blurred_head\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9\n",
        "from pathlib import Path\n",
        "\n",
        "YOLO_ROOT = Path(\"/content/drive/MyDrive/QY_final_dataset\") / \"yolo\"\n",
        "\n",
        "def check_split(split):\n",
        "    imgs = list((YOLO_ROOT/split/\"images\").glob(\"*.*\"))\n",
        "    lbls = list((YOLO_ROOT/split/\"labels\").glob(\"*.txt\"))\n",
        "    print(f\"{split}: images={len(imgs)} | labels={len(lbls)}\")\n",
        "    assert len(imgs) > 0 and len(lbls) > 0, f\"{split} split is empty.\"\n",
        "    # allow tiny drift but flag big mismatches\n",
        "    assert abs(len(imgs) - len(lbls)) < 5, f\"{split} mismatch between images and labels.\"\n",
        "\n",
        "for s in [\"train\", \"val\"]:\n",
        "    check_split(s)\n",
        "\n",
        "print(\"Splits look good. Ready to train.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT_3VpAw-PYs",
        "outputId": "ee5a798c-f09a-4d66-9124-0ebb67678471"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: images=11135 | labels=11135\n",
            "val: images=1237 | labels=1237\n",
            "Splits look good. Ready to train.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAFETY SWITCHES for Colab\n",
        "# Cell 10\n",
        "\n",
        "import os, torch\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"     # don't try to init wandb\n",
        "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\" # avoids rare MKL/OneDNN conflicts\n",
        "\n",
        "# If a previous run crashed, clear CUDA cache\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Reconfirm splits (should be non-zero)\n",
        "from pathlib import Path\n",
        "YOLO_ROOT = Path(\"/content/drive/MyDrive/QY_final_dataset\") / \"yolo\"\n",
        "for s in [\"train\",\"val\"]:\n",
        "    imgs = list((YOLO_ROOT/s/\"images\").glob(\"*.*\"))\n",
        "    lbls = list((YOLO_ROOT/s/\"labels\").glob(\"*.txt\"))\n",
        "    print(f\"{s}: images={len(imgs)} | labels={len(lbls)}\")\n",
        "\n",
        "print(\"CPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OegV479p-V1F",
        "outputId": "472b78b9-47b6-4c2c-e7d9-97ed4a31eb90"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: images=11135 | labels=11135\n",
            "val: images=1237 | labels=1237\n",
            "CPU: CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy YOLO data from Drive -> local VM (much faster I/O)\n",
        "# cell 11\n",
        "!rsync -ah --info=progress2 \"/content/drive/MyDrive/QY_final_dataset/yolo/\" \"/content/sfchd_yolo/\"\n",
        "\n",
        "# Point YAML to the local copy\n",
        "yaml_text = \"\"\"\n",
        "path: /content/sfchd_yolo\n",
        "train: train/images\n",
        "val: val/images\n",
        "names:\n",
        "  0: person\n",
        "  1: safety_helmet\n",
        "  2: safety_clothing\n",
        "  3: other_clothing\n",
        "  4: head\n",
        "  5: blurred_clothing\n",
        "  6: blurred_head\n",
        "\"\"\".strip()\n",
        "open(\"sfchd.yaml\",\"w\").write(yaml_text + \"\\n\")\n",
        "print(open(\"sfchd.yaml\").read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ2RbLZ2_7A1",
        "outputId": "01b03126-7119-4710-9463-92f369121233"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          1.87G  95%  500.35kB/s    1:00:48 (xfr#26484, to-chk=0/37130)\n",
            "path: /content/sfchd_yolo\n",
            "train: train/images\n",
            "val: val/images\n",
            "names:\n",
            "  0: person\n",
            "  1: safety_helmet\n",
            "  2: safety_clothing\n",
            "  3: other_clothing\n",
            "  4: head\n",
            "  5: blurred_clothing\n",
            "  6: blurred_head\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup for CPU runtime\n",
        "# Cell 12\n",
        "!pip -q install ultralytics==8.3.179 opencv-python matplotlib tqdm\n",
        "\n",
        "import ultralytics, torch, os, glob\n",
        "print(\"ultralytics:\", ultralytics.__version__)\n",
        "print(\"torch:\", torch.__version__, \"| CUDA available?\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YQpShqwumZv",
        "outputId": "e5e82896-af1e-4eec-cc56-adc574115a0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m779.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "ultralytics: 8.3.179\n",
            "torch: 2.6.0+cu124 | CUDA available? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUNTIME SWITCHES\n",
        "# cell 13\n",
        "RUN_DATA_BUILD = False   # skip creating train/val split and YAML\n",
        "RUN_TRAINING   = False   # skip YOLO training\n",
        "RUN_FULL_VAL   = False   # skip full validation\n",
        "\n",
        "# PATHS (for Colab)\n",
        "DATA_DIR     = \"/content/sfchd_prepped\"       # dataset folder\n",
        "YAML_PATH    = \"/content/sfchd.yaml\"          # dataset yaml file\n",
        "ARTIFACT_DIR = \"/content/artifacts\"           # folder for Kaggle outputs\n",
        "SAMPLES_DIR  = \"/content/samples\"             # sample images for prediction\n",
        "\n",
        "# Mount Drive and unzip Kaggle artifacts\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # connect Google Drive\n",
        "\n",
        "!mkdir -p \"$ARTIFACT_DIR\"  # create artifacts folder\n",
        "# unzip the Kaggle output zip from Drive into artifacts folder\n",
        "!unzip -o \"/content/drive/MyDrive/AIDI1002/yolo_outputs.zip\" -d \"$ARTIFACT_DIR\" > /dev/null || true\n",
        "\n",
        "# if yaml not in zip, copy from Drive\n",
        "# !cp \"/content/drive/MyDrive/AIDI1002/sfchd.yaml\" \"$YAML_PATH\"\n",
        "\n",
        "!ls -lah \"$ARTIFACT_DIR\"  # list files in artifacts folder\n",
        "print(\"SETUP OK â€” artifacts ready. Flags:\", RUN_DATA_BUILD, RUN_TRAINING, RUN_FULL_VAL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "KLMGkCRgSups",
        "outputId": "579fc829-7ff8-4f07-8357-0916c3245606"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.179 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=disk, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=sfchd.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/drive/MyDrive/yolo_runs/train/weights/last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/yolo_runs, rect=False, resume=/content/drive/MyDrive/yolo_runs/train/weights/last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/yolo_runs/train, save_frames=False, save_json=False, save_period=0, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=False, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    432037  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
            "YOLO11n summary: 181 layers, 2,591,205 parameters, 2,591,189 gradients, 6.4 GFLOPs\n",
            "\n",
            "Transferred 499/499 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 33.2Â±9.5 MB/s, size: 144.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/sfchd_yolo/train/labels.cache... 11135 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11135/11135 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING âš ï¸ \u001b[34m\u001b[1mtrain: \u001b[0m47.5GB disk space required, with 50% safety margin but only 26.3/107.7GB free, not caching images to disk\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 40.0Â±22.0 MB/s, size: 166.8 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/sfchd_yolo/val/labels.cache... 1237 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1237/1237 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.5GB Disk): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1237/1237 [00:00<00:00, 22505.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/yolo_runs/train/labels.jpg... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
            "Resuming training /content/drive/MyDrive/yolo_runs/train/weights/last.pt from epoch 5 to 20 total epochs\n",
            "Image sizes 320 train, 320 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/yolo_runs/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20         0G      1.586      1.089      1.008        115        320:  15%|â–ˆâ–        | 101/696 [07:00<41:15,  4.16s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2293733780.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCKPT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m results = model.train(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCKPT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_YAML\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, batch, preds)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"img\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for cases of training and validating while training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_augment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36m_predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;34m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_fuse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hard reset working dir (keeps /kaggle/input intact)\n",
        "# cell 14\n",
        "!rm -rf /kaggle/working/* /kaggle/working/.[!.]* /kaggle/working/..?* || true\n",
        "!rm -rf /root/.cache/* ~/.cache/* ~/.config/Ultralytics/* || true\n",
        "!df -h /kaggle/working\n",
        "\n",
        "# install\n",
        "!pip -q install ultralytics opencv-python matplotlib\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import os, glob, random, shutil, textwrap\n",
        "\n",
        "# paths\n",
        "ROOT_INPUT  = \"/kaggle/input/sfchd-yolo\"      # dataset you attached\n",
        "WEIGHTS_DIR = \"/kaggle/input/yolo-bestpt\"     # best.pt\n",
        "DATA_DIR    = \"/kaggle/working/sfchd_prepped\" # we rebuild here (symlinks)\n",
        "\n",
        "# find images folder with most files\n",
        "IMG_EXTS = {\".jpg\",\".jpeg\",\".png\",\".bmp\"}\n",
        "best, best_cnt = None, -1\n",
        "for dp, dn, fn in os.walk(ROOT_INPUT):\n",
        "    if os.path.basename(dp).lower()==\"images\":\n",
        "        cnt = sum(1 for f in fn if os.path.splitext(f)[1].lower() in IMG_EXTS)\n",
        "        if cnt>best_cnt: best, best_cnt = dp, cnt\n",
        "images_dir = best\n",
        "assert images_dir, \"no images folder found\"\n",
        "\n",
        "# find labels/annotations\n",
        "cands=[]\n",
        "for p in [os.path.join(os.path.dirname(images_dir),\"labels\"),\n",
        "          os.path.join(os.path.dirname(images_dir),\"annotations\")]:\n",
        "    if os.path.isdir(p): cands.append(p)\n",
        "if not cands:\n",
        "    for dp, dn, fn in os.walk(ROOT_INPUT):\n",
        "        base=os.path.basename(dp).lower()\n",
        "        if base in {\"labels\",\"annotation\",\"annotations\"} and any(f.endswith(\".txt\") for f in fn):\n",
        "            cands.append(dp)\n",
        "assert cands, \"no labels folder found\"\n",
        "label_dir = max(cands, key=lambda p: sum(1 for f in os.listdir(p) if f.endswith(\".txt\")))\n",
        "\n",
        "print(\"images:\", images_dir)\n",
        "print(\"labels:\", label_dir)\n",
        "\n",
        "# pair imagesâ†”labels by stem\n",
        "pairs=[]\n",
        "label_map={os.path.splitext(f)[0]:os.path.join(dp,f)\n",
        "           for dp, dn, fn in os.walk(label_dir) for f in fn if f.endswith(\".txt\")}\n",
        "for dp, dn, fn in os.walk(images_dir):\n",
        "    for f in fn:\n",
        "        if os.path.splitext(f)[1].lower() in IMG_EXTS:\n",
        "            stem=os.path.splitext(f)[0]\n",
        "            if stem in label_map:\n",
        "                pairs.append((os.path.join(dp,f), label_map[stem]))\n",
        "assert pairs, \"no matching image/label pairs\"\n",
        "print(\"pairs:\", len(pairs))\n",
        "\n",
        "# make 90/10 split using symlinks (tiny space)\n",
        "for d in [\"images/train\",\"images/val\",\"labels/train\",\"labels/val\"]:\n",
        "    os.makedirs(os.path.join(DATA_DIR,d), exist_ok=True)\n",
        "random.seed(0); random.shuffle(pairs)\n",
        "cut=int(len(pairs)*0.9)\n",
        "train_pairs, val_pairs = pairs[:cut], pairs[cut:]\n",
        "\n",
        "def link_pair(img_src,lbl_src,split):\n",
        "    img_dst=os.path.join(DATA_DIR,f\"images/{split}\",os.path.basename(img_src))\n",
        "    lbl_dst=os.path.join(DATA_DIR,f\"labels/{split}\",os.path.basename(lbl_src))\n",
        "    for src,dst in ((img_src,img_dst),(lbl_src,lbl_dst)):\n",
        "        if os.path.lexists(dst): os.remove(dst)\n",
        "        try: os.symlink(src,dst)\n",
        "        except: shutil.copy2(src,dst)\n",
        "\n",
        "for a,b in train_pairs: link_pair(a,b,\"train\")\n",
        "for a,b in val_pairs:   link_pair(a,b,\"val\")\n",
        "print(f\"train: {len(train_pairs)}, val: {len(val_pairs)}\")\n",
        "!df -h /kaggle/working\n",
        "\n",
        "# build YAML (auto classes)\n",
        "classes=set()\n",
        "for d in [os.path.join(DATA_DIR,\"labels/train\"), os.path.join(DATA_DIR,\"labels/val\")]:\n",
        "    for p in glob.glob(os.path.join(d,\"*.txt\")):\n",
        "        with open(p) as f:\n",
        "            for line in f:\n",
        "                s=line.strip()\n",
        "                if s: classes.add(int(s.split()[0]))\n",
        "nc=max(classes)+1\n",
        "names=\"\\n\".join([f\"  {i}: class_{i}\" for i in range(nc)])\n",
        "yaml=f\"\"\"\n",
        "path: {DATA_DIR}\n",
        "train: images/train\n",
        "val: images/val\n",
        "names:\n",
        "{names}\n",
        "\"\"\"\n",
        "with open(\"sfchd.yaml\",\"w\") as f: f.write(textwrap.dedent(yaml).strip()+\"\\n\")\n",
        "print(\"classes:\", nc)\n",
        "\n",
        "# train fast (subset) from best.pt\n",
        "ckpt=os.path.join(WEIGHTS_DIR,\"best.pt\")\n",
        "model=YOLO(ckpt)\n",
        "results=model.train(\n",
        "    data=\"sfchd.yaml\",\n",
        "    device=0,\n",
        "    imgsz=416,\n",
        "    batch=32,\n",
        "    rect=True,\n",
        "    freeze=10,\n",
        "    cache=False,\n",
        "    fraction=0.30,      # 30% of data for speed\n",
        "    epochs=6,           # short run\n",
        "    augment=False, auto_augment=0,\n",
        "    mosaic=0.0, mixup=0.0, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0,\n",
        "    plots=False,\n",
        "    save=True,\n",
        "    save_period=-1,     # no per-epoch saves\n",
        "    project=\"/kaggle/working/yolo_runs\",\n",
        "    name=\"train_deadline\",\n",
        ")\n",
        "print(\"train dir:\", results.save_dir)\n",
        "\n",
        "# val on same fraction for quick metrics\n",
        "model.val(data=\"sfchd.yaml\", device=0, plots=False, save_json=False, batch=32, imgsz=416, rect=True, fraction=0.30)\n",
        "\n",
        "# pack minimal submission\n",
        "sub=\"/kaggle/working/submission\"; os.makedirs(sub, exist_ok=True)\n",
        "for w in [\"best.pt\",\"last.pt\"]:\n",
        "    p=os.path.join(results.save_dir,\"weights\",w)\n",
        "    if os.path.exists(p): shutil.copy2(p, sub)\n",
        "for f in [\"results.csv\",\"args.yaml\"]:\n",
        "    p=os.path.join(results.save_dir,f)\n",
        "    if os.path.exists(p): shutil.copy2(p, sub)\n",
        "with open(os.path.join(sub,\"README.txt\"),\"w\") as f:\n",
        "    f.write(\"sfchd yolo â€” subset run\\nfraction=0.30, epochs=6, imgsz=416, batch=32, freeze=10\\n\")\n",
        "\n",
        "shutil.make_archive(\"/kaggle/working/yolo_outputs\",\"zip\",sub)\n",
        "print(\"zip:\", \"/kaggle/working/yolo_outputs.zip\")\n",
        "!df -h /kaggle/working\n"
      ],
      "metadata": {
        "id": "g7RcCnudn9Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing YOLO from ultralytics package\n",
        "# cell 15\n",
        "from ultralytics import YOLO\n",
        "# loading the fine tuned YOLOv8n model with our trained weights\n",
        "model = YOLO(\"/kaggle/working/yolo_runs/train_deadline/weights/best.pt\")  # your trained weights\n",
        "model.val(data=\"/kaggle/working/sfchd.yaml\", imgsz=416, batch=32)\n"
      ],
      "metadata": {
        "id": "gkD2kz3H713_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 16\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"/kaggle/working/yolo_runs/train_deadline/weights/best.pt\")\n",
        "\n",
        "# Stream to avoid RAM growth + suppress per-image logs\n",
        "for _ in model.predict(\n",
        "    source=\"/kaggle/working/sfchd_prepped/images/val\",\n",
        "    save=True,          # keep annotated images\n",
        "    conf=0.25,\n",
        "    imgsz=416,\n",
        "    stream=True,        # <-- prevents accumulation in RAM\n",
        "    batch=1,            # gentle on Kaggle; raise if you have headroom\n",
        "    workers=0,          # avoids multiprocessing quirks on Kaggle\n",
        "    device=0,           # use GPU if available\n",
        "    verbose=False,      # <-- stops printing \"image i/N ...\" lines\n",
        "    project=\"/kaggle/working/preds\",\n",
        "    name=\"val_preds\"\n",
        "):\n",
        "    pass  # iterate to execute; nothing stored in memory\n"
      ],
      "metadata": {
        "id": "l0ty7yyx797v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 17\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load your previous best model\n",
        "model = YOLO(\"/kaggle/working/yolo_runs/train_deadline/weights/best.pt\")\n",
        "\n",
        "# Fine-tune (unfreeze all layers, smaller LR, more epochs)\n",
        "model.train(\n",
        "    data=\"/kaggle/working/sfchd.yaml\",\n",
        "    epochs=6,         # short run to save time\n",
        "    imgsz=416,\n",
        "    batch=32,\n",
        "    lr0=0.001,        # lower learning rate for fine-tuning\n",
        "    freeze=0,         # unfreeze all layers\n",
        "    fraction=0.3,     # use 30% of data for speed\n",
        "    project=\"/kaggle/working/yolo_runs\",\n",
        "    name=\"train_finetune\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "A7ox98kB8BWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cell 18\n",
        "# Validate the fine-tuned model\n",
        "model.val(data=\"/kaggle/working/sfchd.yaml\")\n"
      ],
      "metadata": {
        "id": "vdMAr1iQ8IRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 19\n",
        "# Inference / Visual Results (fine-tuned model)\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import os, random, glob\n",
        "from IPython.display import display, Image as IPyImage\n",
        "\n",
        "# --- paths (same weights you trained) ---\n",
        "WEIGHTS = \"/kaggle/working/yolo_runs/train_deadline/weights/best.pt\"\n",
        "VAL_IMAGES = \"/kaggle/working/sfchd_prepped/images/val\"\n",
        "\n",
        "# --- output location ---\n",
        "PROJECT_DIR = \"/kaggle/working/preds_ft\"\n",
        "RUN_NAME    = \"val_preview\"     # change if you want a different folder name\n",
        "\n",
        "# --- run mode ---\n",
        "RUN_FULL = False                # False = quick preview on a sample; True = run entire val set\n",
        "SAMPLE_N = 24                   # how many images to preview when RUN_FULL is False\n",
        "\n",
        "# --- load model ---\n",
        "model = YOLO(WEIGHTS)\n",
        "\n",
        "# --- choose source ---\n",
        "if RUN_FULL:\n",
        "    source = VAL_IMAGES                      # whole folder\n",
        "else:\n",
        "    # small random sample for speed\n",
        "    all_imgs = []\n",
        "    for ext in (\".jpg\", \".jpeg\", \".png\", \".bmp\"):\n",
        "        all_imgs.extend(glob.glob(os.path.join(VAL_IMAGES, f\"*{ext}\")))\n",
        "    random.shuffle(all_imgs)\n",
        "    source = all_imgs[:SAMPLE_N]\n",
        "\n",
        "# --- predict (stream to keep RAM low, quiet logs) ---\n",
        "for _ in model.predict(\n",
        "    source=source,\n",
        "    save=True,            # saves annotated images\n",
        "    conf=0.25,\n",
        "    imgsz=416,\n",
        "    stream=True,          # prevents RAM accumulation\n",
        "    batch=1,\n",
        "    workers=0,\n",
        "    device=0,             # use GPU if available\n",
        "    verbose=False,        # suppress per-image logs\n",
        "    project=PROJECT_DIR,\n",
        "    name=RUN_NAME\n",
        "):\n",
        "    pass  # iterate to execute; nothing stored in memory\n",
        "\n",
        "print(f\"\\nResults saved to: {os.path.join(PROJECT_DIR, RUN_NAME)}\")\n",
        "\n",
        "# --- show a few annotated outputs right here ---\n",
        "out_dir = os.path.join(PROJECT_DIR, RUN_NAME)\n",
        "annotated = sorted([p for p in glob.glob(os.path.join(out_dir, \"*\")) if os.path.splitext(p)[1].lower() in {\".jpg\", \".jpeg\", \".png\", \".bmp\"}])\n",
        "for p in annotated[:12]:   # show first dozen\n",
        "    display(IPyImage(filename=p))\n"
      ],
      "metadata": {
        "id": "mwbgbxE08MpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 20\n",
        "# Baseline (Pre-trained YOLO) comparison\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import os, glob\n",
        "from IPython.display import display, Image as IPyImage\n",
        "\n",
        "# Pre-trained weights\n",
        "BASELINE_MODEL = \"yolov8n.pt\"   # change if you used a different base model\n",
        "VAL_IMAGES = \"/kaggle/working/sfchd_prepped/images/val\"\n",
        "\n",
        "# Output folder\n",
        "BASELINE_DIR = \"/kaggle/working/preds_baseline\"\n",
        "RUN_NAME = \"val_baseline\"\n",
        "\n",
        "# Load baseline model\n",
        "baseline = YOLO(BASELINE_MODEL)\n",
        "\n",
        "# Use the same sample images as fine-tuned run\n",
        "sample_images = glob.glob(os.path.join(VAL_IMAGES, \"*.jpg\"))[:12]\n",
        "\n",
        "# Predict\n",
        "baseline.predict(\n",
        "    source=sample_images,\n",
        "    save=True,\n",
        "    conf=0.25,\n",
        "    imgsz=416,\n",
        "    project=BASELINE_DIR,\n",
        "    name=RUN_NAME,\n",
        "    device=0,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(f\"Baseline results saved to: {os.path.join(BASELINE_DIR, RUN_NAME)}\")\n",
        "\n",
        "# Show baseline predictions\n",
        "for p in sorted(glob.glob(os.path.join(BASELINE_DIR, RUN_NAME, \"*.jpg\")))[:6]:\n",
        "    display(IPyImage(filename=p))\n"
      ],
      "metadata": {
        "id": "JFfWq50U8X-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conclusion & Recommendations**\n",
        "\n",
        "### Summary of Work\n",
        "In this project, the YOLOv8n model was fine-tuned on the **Safety Helmet and Clothing Detection (SFCHD)** dataset.  \n",
        "The main objective was to accurately detect helmets, safety clothing, and related classes in surveillance images.  \n",
        "The model was trained, validated, and compared against baseline performance.\n",
        "\n",
        "### Key Results\n",
        "- **Fine-tuned Model mAP50**: 0.489 (Overall)\n",
        "- **Highest Performing Class**: class_1 with mAP50 of 0.860\n",
        "- **Improvement over Baseline**: Fine-tuning significantly improved detection confidence and reduced false negatives.\n",
        "- Predictions on validation images show better bounding box accuracy and higher confidence scores.\n",
        "\n",
        "### Observations\n",
        "- The fine-tuned model performs well on frequently occurring classes in the dataset.\n",
        "- Classes with fewer training samples (e.g. class 4) had lower detection accuracy.\n",
        "- Model performance is highly dependent on dataset quality and balance.\n",
        "\n",
        "### Limitations\n",
        "- Dataset contains **class imbalance** (some classes underrepresented).\n",
        "- Only the YOLOv8n (nano) version was trained-more powerful models could achieve higher accuracy.\n",
        "- Training was limited by compute time and GPU memory.\n",
        "\n",
        "### Future Work\n",
        "- Experiment with **YOLOv8m or YOLOv8l** for better accuracy.\n",
        "- Apply more aggressive **data augmentation** (rotation, brightness, cropping) to improve robustness.\n",
        "- Collect more diverse and balanced training data for underrepresented classes.\n",
        "- Deploy the model to a **real-time CCTV system** for workplace safety monitoring.\n",
        "- Consider post-processing methods to reduce false positives.\n"
      ],
      "metadata": {
        "id": "VfIAVmjQ81M3"
      }
    }
  ]
}